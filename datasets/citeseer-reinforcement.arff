@relation "citeseer-reinforcement"

@attribute reference string
@attribute class {'279', '51', '54', '57', '201', '204', '123', '522', '441', '360', '207', '126', '525', '444', '363', '282', '447', '285', '369', '63', '66', '69', '210', '3', '213', '6', '450', '216', '9', '135', '453', '372', '291', '138', '456', '459', '378', '72', '75', '78', '300', '303', '141', '222', '306', '144', '225', '462', '381', '309', '147', '228', '465', '384', '468', '387', '81', '84', '150', '231', '315', '153', '234', '471', '390', '318', '156', '237', '474', '159', '396', '477', '12', '399', '15', '18', '90', '96', '240', '321', '402', '162', '324', '405', '165', '246', '327', '408', '480', '249', '483', '486', '21', '24', '27', '330', '411', '171', '252', '333', '414', '174', '255', '336', '417', '177', '339', '492', '495', '498', '33', '36', '39', '102', '501', '105', '420', '504', '261', '342', '423', '507', '183', '264', '345', '426', '267', '348', '189', '42', '45', '111', '510', '114', '513', '117', '270', '351', '432', '516', '192', '273', '354', '435', '519', '195', '276', '357', '438'}


@data
"Baird, L.C., & Klopf, A. H. (1993). Reinforcement learning with highdimensional, continuous actions Wright-Patterson Air Force Base, OH. (Wright Laboratory technical report WL-TR-93-1147, available from the Defense Technical information Center, Cameron S", '3'
"Pendrith, M. (1994). On reinforcement learning of control actions in noisy and non-markovian domans. Technical Report UNSW-CSE-TR-9410, School of Computer Science and Engineering, The University of New South Wales.", '6'
"M.D. Pendrith. On reinforcement learning of control actions in noisy and non-Markovian domains. Tech. report, UNSW-CSE-TR-9410, School of Comp. Sci. and Eng., Uni. of NSW, Australia, 1994.", '6'
"Moriarty, D. E., and Miikkulainen, R. (1994a). Efficient reinforcement learning through symbiotic evolution. Technical Report AI94-224, Department of Computer Sciences, The University of Texas at Austin.", '9'
"R.S. Sutton, Temporal credit assignment in reinforcement learning, Ph.D. Thesis, Department of Computer and Information Science, University of Massachussets,1984.", '12'
"Sutton, R. S. (1984). Temporal credit assignment in reinforcement learning. PhD thesis, University of Massachusetts, Amherst.", '12'
"R. S. Sutton. Temporal Credit Assignment in Reinforcement Learning. Phd. thesis, University of Massachusetts, Amherst, 1984.", '12'
"Sutton, R. S. (1984). Temporal credit assignment in  reinforcement learning. Ph.D. Dissertation, University of Massachusetts, Amherst (also COINS Technical Report 84-02).", '12'
"Sutton, R. S., 1984. Temporal credit assignment in reinforcement learning. Ph.D. dissertation, Dept. of computer and information science, University of Massachusetts, Amherst, MA.", '12'
"R. S. Sutton. Temporal Credit Assignment in Reinforcement Learning. Phd. thesis, University of Massachusetts, Amherst, 1984.", '12'
"Sutton, R.S. Temporal credit assignment in reinforcement learning Ph.D. dissertation at University of Massachusets (1984).", '12'
"Sutton, R. S. (1984). Temporal Credit Assignment in Reinforcement Learning. PhD thesis, University of Massachusetts, Amherst, Massachusetts.", '12'
"R. S. Sutton. Temporal Credit Assignment in Reinforcement Learning. PhD thesis, University of Massachusetts, Dept. of Comp. and Inf. Sci., 1984.", '12'
"Sutton, R. S. (1984). Temporal credit assignment in reinforcement learning. Ph.D. Dissertation, Department of Computer and Information Science, University of Massachusetts, Amherst (also COINS Technical Report 84-02).", '12'
"Sutton, R.S. 1984. Temporal credit assignment in reinforcement learning. University of Massachusetts. Departement of Computer and Information Science. Technical Report 84-2. Amherst, MA.", '12'
"Steven D. Whitehead and Dana H. Ballard. A study of cooperative mechanisms for faster reinforcement learning. TR 365, Computer Science Dept., University of Rochester, Feburary 1991.", '15'
"S.D. Whitehead, A study of cooperative mechanisms for faster reinforcement learning, TR-365, Computer Science Dept., University of Rochester, 1991.", '15'
"Whitehead, Steven D. (1991). A study of cooperative mechanisms for faster reinforcement learning. Technical Report 365. University of Rochester, Computer Science Department.", '15'
"Whitehead,S.D. (1991a). A study of cooperative mechanisms for faster reinforcement learning. TR 365, Computer Science Dept., University of Rochester.", '15'
"Whitehead, S. D., 1991b. A study of cooperative mechanisms for faster reinforcement learning. Technical Report CS-365, University of Rochester, NY.", '15'
"R. Andrew McCallum. First results with utile distinction memory for reinforcement learning. Technical Report 446, University of Rochester Computer Science Dept., 1992.  25", '18'
"R. Andrew McCallum. First results with utile distinction memory for reinforcement learning. Technical Report 446, University of Rochester Computer Science Dept., 1992.  40", '18'
"McCallum, R. A. (1992). First results with utile distinction memory for reinforcement learning. Technical Report 446, Dept. Comp. Sci., Univ.", '18'
"Long-Ji Lin and Tom Mitchell. Memory approaches to reinforcement learning in nonmarkovian domains. Technical Report CMU-CS-92138, School of Computer Science, Carnegie Mellon University, 1992.", '21'
"L.-J. Lin and T. Mitchell. Memory approaches to reinforcement learning in nonMarkovian domains. Technical Report CMU-CS-92-138, Carnegie Mellon University, May 1992.", '21'
"Littman, M. L., and Boyan, J. A. (1993). A distributed reinforcement learning scheme for network routing. Technical Report CMU-CS-93-165, School of Computer Science, Carnegie Mellon University.", '24'
"M. Littman and J. Boyan. A distributed reinforcement learning scheme for network routing. Technical Report CMU-CS-93-165, School of Computer Science, Carnegie Mellon University, 1993.", '24'
"L.J. Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, Pittsburgh, January 1993.", '27'
"L-J. Lin, Reinforcement learning for robots using neural networks, Ph.D. Thesis, Carnegie Mellon University, Pittsburgh, Pennsylvania,1993.", '27'
"Lin, L. (1993). Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, Pittsburgh.", '27'
"Lin, L. J. (1993). Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, Pittsburgh, PA. Technical Report CMU-CS-93-103.", '27'
"Lin, L. (1993). Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, Pittsburgh.", '27'
"L.-J. Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, 1993.", '27'
"L.-J. Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, 1993.", '27'
"Long-Ji Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon, School of Computer Science, January 1993.", '27'
"Long-Ji Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon, School of Computer Science, January 1993.", '27'
"Long-Ji Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, January 1993.", '27'
"Lin L.-J., Reinforcement Learning for Robots using Neural Networks, PhD thesis, Carnegie Mellon University, School of Computer Science, 1992.", '27'
"L.-J. Lin. Reinforcement Learning for Robots Using Neural Networks. PhD thesis, School of Computer Science, Carnegie Mellon University, 1993.", '27'
"Steven Whitehead. Reinforcement Learning for the Adaptive Control of Perception and Action. PhD thesis, Department of Computer", '33'
"Steven Whitehead. Reinforcement Learning for the Adaptive Control of Perception and Action. PhD thesis, Department of Computer Science, University of Rochester, 1992.", '33'
"Whitehead, S.D. (1992). Reinforcement learning for the adaptive control of perception and action Tech. Rep.", '33'
"Whitehead, S. (1992). Reinforcement Learning for the Adaptive Control of Perception and Action. PhD thesis, University of Rochester.", '33'
"M.A. Pokorny, A Method of Tuning Fuzzy Sets by Reinforcement Learning, Master's Thesis, Department of Computer Science and Engineering, Univ. of South Florida, Tampa, Fl., April 1996.", '36'
"Buijtenen W.M., Schram G., Babu>=ska R., Verbruggen H.B. (1996), Adaptive fuzzy control of satellite attitude by reinforcement learning. Submitted to IEEE transactions on Fuzzy Systems.", '39'
"Ram, A. and J.C. Santamaria, A multistrategy case-based and reinforcement learning approach to self-improving reactive control systems for autonomous robotic navigation. In Proc. of the Second International Workshop on MultiStrategy Learning, 1993.", '42'
"Ram, A. and J.C. Santamaria, A multistrategy case-based and reinforcement learning approach to self-improving reactive control systems for autonomous robotic navigation. In Proc. of the Second International Workshop on MultiStrategy Learning, 1993.", '42'
"Ilg W., Berns K. (1995), A learning architecture based on reinforcement learning for adaptive control of the walking machine LAURON. Robotics and Autonomous Systems, Vol 15, pp 321-334.", '45'
"M. Asada, S. Noda, S. Tawaratsumida, and K. Hosoda. Vision-based reinforcement learning for purposive behavior acquisition. In Proc. of IEEE Int. Conf. on Robotics and Automation, pages 146-153, 1995.  Figure 7: The robot succeeded i", '51'
"Asada, M., S. Noda, S. Tawaratsumida and K. Hosoda (1995). Vision-based reinforcement learning for purposive behavior acquisition. In: Proc. of IEEE Int. Conf. on Robotics and Automation. pp. 146-153.", '51'
"Asada, M., S. Noda, S. Tawaratsumida and K. Hosoda (1994b). Vision-based behavior acquisition for a shooting robot by using a reinforcement learning.", '54'
"M. Asada,S. Noda, S. Tawaratsumida and K. Hosoda, Purposive Behavior Acquisition On A Real Robot By A Vision-Based Reinforcement Learning, Proceedings of the MLT-COLT 94 Workshop on Robot Learning, New Brunswick, N.J., 1-9, 1994 .", '57'
"Minoru Asada, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda. Purposive behavior acquisition on a real robot by visionbased reinforcement learning. In Proc. of MLC-COLT (Machine Learning Confernce and Computer Learning Theory) W", '57'
"Asada, M., S. Noda, S. Tawaratsumida and K. Hosoda (1994a). purposive behavior acquisition on a real robot by vision-based reinforcement learning. In: Proc. of MLC-COLT (Machine Learning Conference and Computer Learning Theory) Workshop on Robot Learni", '57'
"Minoru Asada, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda. Purposive behav ior acquisition for a real robot by visionbased reinforcement learnin. Machine Learning, 12((2/3)):279303, May 1996.", '63'
"M. Asada, S. Noda, S. Tawaratumida, and K. Hosoda. Purposive behavior acquisition for a real robot by vision-based reinforcement learning. Machine Learning, 23:279-303, 1996.", '63'
"M. Asada, S. Noda, S. Tawaratumida, and K. Hosoda. Purposive behavior acquisition for a real robot by vision-based reinforcement learning. Machine Learning, 23:279-303, 1996.", '63'
"M. Asada, S. Noda, S. Tawaratumida, and K. Hosoda. Purposive behavior acquisition for a real robot by visionbased reinforcement learning. Machine Learning, 23:279 303, 1996.", '63'
"M. Asada, S. Noda, S. Tawaratumida, and  K. Hosoda. Purposive behavior acquisition for a real robot by vision-based reinforcement learning. Machine Learning, 23:279-303, 1996.", '63'
"Minoru Asada, Shoichi Noda, Sukoya Tawaratumida, and Koh Hosoda. Purposive behavior acquisition for a real robot by vision-based reinforcement learning. Machine Learning, 23:279-303, 1996.", '63'
"M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. coordination of multiple behaviors acquired by vision-based reinforcement learning. In Proc. of IEEE/RSJ/GI International Conference on Intelligent Robots and Systems", '66'
"Minoru Asada, Eiji Uchibe, Shoichi Noda, Sukoya Tawaratsumida, and Koh Hosoda. Coordination of multiple behaviors acquired by vision-based reinforcement learning. In Proc. of IEEE/RSJ/GI International Conference  on Intelligent Robo", '66'
"M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. Coordination of multiple behaviors acquired by visionbased reinforcement learning. In Proc. of IEEE/RSJ/GI International Conference on Intelligent Robots and Systems 1994 (IROS '94), page", '66'
"M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. Coordination of multiple behaviors acquired by visionbased reinforcement learning. In Proc. of the International Conference on Intelligent Robots and Systems), pages 917924, 1994.", '66'
"Asada, M.; Uchibe, E.; Noda, S.; Tawaratsumida, S.; and Hosoda, K. 1994. Coordination of multiple behaviors acquired by vision-based reinforcement learning. In Proceedings of IROS-94.", '66'
"M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. Coordination of multiple behaviors acquired by vision-based reinforcement learning. In Proc. of IEEE/RSJ/GI International Conference on Intelligent Robots and Systems 1994 (IROS '94), pages 9", '66'
"Eiji Uchibe, Minoru Asada, and Koh Hosoda. Behavior coordination for a mobile robot using modular reinforcement learning. In Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems 1996 (IROS '96), pages 1329-13", '69'
"Eiji Uchibe, Minoru Asada, and Koh Hosoda. Behavior coordination for a mobile robot using modular reinforcement learning. In Proc. of IEEE/RSJ International Conference on Intelligent Robots and Systems 1996 (IROS '96), pages 13291336, 1996.", '69'
"M. Asada, E. Uchibe, S. Noda, S. Tawaratsumida, and K. Hosoda. A vision-based reinforcement learning for coordination of soccer playing behaviors. In Proc. of AAAI-94 Workshop on AI and A-life and Entertainment, pages 16-21, 1994.", '72'
"M. Dorigo and M. Colombetti, The role of the Trainer in Reinforcement Learning, Proceedings of the MLT-COLT 94 Workshop on Robot Learning, New Brunswick, N.J., 37-45, 1994.", '75'
"Gambardella, L. M. and Dorigo, M., 1995, Ant-Q: A Reinforcement Learning approach to the traveling salesman problem, in: Proceedings of ML-95, Twelfth International Conference on Machine Learning, A. Prieditis and S. Russell (eds.) (Morgan Kaufmann, San", '78'
"L. M. Gambardella and M. Dorigo. Ant-Q: A Reinforcement Learning Approach to the Traveling Salesman Problem. In Proceedings of the Twelfth Iternational Conference on Machine Learning, pages 252-260. Morgan Kaufmann, 1995.", '78'
"L. M. Gambardella and M. Dorigo. Ant-Q: A Reinforcement Learning Approach to the Traveling Salesman Problem. In Proceedings of the Twelfth Iternational Conference on Machine Learning, pages 252-260. Morgan Kaufmann, 1995.", '78'
"Gambardella, L. M. and Dorigo, M., 1995, Ant-Q: A Reinforcement Learning approach to the traveling salesman problem, in: Proceedings of ML-95, Twelfth International Conference on Machine Learning, A. Prieditis and S. Russell (eds.) (Morgan Kaufmann, San", '78'
"R. A. McCallum. Instance-based utile distinctions for reinforcement learning with hidden state. In A. Prieditis and S. Russell, editors, Machine Learning: Proceedings of the Twelfth International Conference, pages 387-395. Morgan Kaufmann Publishers", '81'
"McCallum, R. A. (1995). Instance-based utile distinctions for reinforcement learning with hidden state. In Prieditis, A. and Russell, S., editors, Machine Learning: Proceedings of the Twelfth International Conference, pages 387-395. Morgan Kaufmann Publi", '81'
"R. Andrew McCallum. Instance-based utile distinctions for reinforcement learning with hidden state. In Proceedings of the Twelfth International Conference on Machine Learning, pages 387-395, San Francisco, CA, 1995. Morgan Kaufmann.", '81'
"Baird, L.C. (1995). Residual Algorithms: Reinforcement Learning with Function Approximation. In Armand Prieditis & Stuart Russell, eds. Machine Learning: Proceedings of the Twelfth International Conference, 9-12 July, Morgan Kaufman Publishers, San Franc", '84'
"Baird, L. C. (1995). Residual Algorithms: Reinforcement Learning with Function Approximation. In Armand Prieditis & Stuart Russell, eds. Machine Learning: Proceedings of the Twelfth International Conference, 9-12 July, Morgan Kaufman Publishers, San Fran", '84'
"Baird, L. C. (1995) Residual Algorithms: Reinforcement Learning with Function Approximation, in Prieditis & Russell, eds. Machine Learning: Proceedings of the Twelfth International Conference, 9-12 July, Morgan Kaufman Publishers, San Francisco, CA.", '84'
"Michael L. Littman. Markov games as a framework for multiagent reinforcement learning. In Proceedings of the Eleventh International Conference on Machine Learning, pages 157163, San Mateo, CA, 1994. Morgan Kaufman.", '90'
"M. L. Littman. Markov games as a framework for multi-agent reinforcement learning. In Proc. of Conf. on Machine Learning-1994, pages 157-163, 1994.", '90'
"Michael L. Littman. Markov games as a framework for multi-agent reinforcement learning. Proceedings of the eleventh International Conference on Machine Learning, pages 157-163, July 1994.", '90'
"Littman, M. L. (1994). Markov games as a framework for multi-agent reinforcement learning. In Proceedings of the Eleventh International Conference on Machine Learning, pages 157-163, San Francisco, CA. Morgan Kaufmann.", '90'
"Littman, M. (1994) Markov Games as a Framework for Multi-agent Reinforcement Learning. Machine Learning: Proceedings of the Eleventh International Conference.", '90'
"Mahadevan, S. (1992). Enhancing transfer in reinforcement learning by building stochastic models of robot actions. In Proceedings of the Ninth International Conference on Machine Learning (pp. 290-299). San Mateo, CA: Morgan Kaufmann Publishers.", '96'
"Mahadevan, S. 1992. Enhancing transfer in reinforcement learning by building stochastic models of robot actions. In Proceedings of the Ninth International Conference on Machine Learning (pp. 290-299). San Mateo, CA: Morgan Kaufmann Publishers.", '96'
"S. Mahadevan. Enhancing Transfer in Reinforcement Learning by Building Stochastic Models of Robot Actions. In Machine Learning: Proceedings of the Ninth International Workshop. Morgan Kaufmann, June 1992.", '96'
"Mahadevan, S., 1992. Enhancing transfer in reinforcement learning by building stochastic models of robots actions. Proceedings of the 9th Conference on Machine Learning, Aberdeen, Scotland, 290299.", '96'
"Satinder P. Singh. Scaling reinforcement learning algorithms by learning variable temporal resolution models. In The Proceedings of the Ninth Internation Machine Learning Conference. Morgan Kaufmann Publishers, Inc., 1992.", '102'
"Singh, S., Scaling reinforcement learning algorithms by learning variable temporal resolution models. In Proc. of the Ninth International Workshop on Machine Learning, 1992.", '102'
"Singh, S., Scaling reinforcement learning algorithms by learning variable temporal resolution models. In Proc. of the Ninth International Workshop on Machine Learning, 1992.", '102'
"Singh, S., Scaling reinforcement learning algorithms by learning variable temporal resolution models. In Proc. of the Ninth International Workshop on Machine Learning, 1992.", '102'
"R. Andrew McCallum. Using transitional proximity for faster reinforcement learning. In The Proceedings of the Ninth International Machine Learning Conference. Morgan Kaufmann Publishers, Inc., 1992.", '105'
"Jeffery A. Clouse and Paul E. Utgoff. A teaching method for reinforcement learning. In The Proceedings of the Ninth International Machine Learning Conference. Morgan Kaufmann Publishers, Inc., 1992.", '111'
"Clouse, J. & Utgoff, P. (1992). A teaching method for reinforcement learning. In Machine Learning: Proceedings of the Ninth International Workshop, (pp. 92-101), Aberdeen, Scotland.", '111'
"Clouse, J. and P. Utgoff, A teaching method for reinforcement learning. In Proc. of the Ninth International Workshop on Machine Learning, 1992.", '111'
"Clouse, J.A., Utgoff, P.E. (1992). A teaching method for reinforcement learning. In: Proceedings of the MLC'92, San Mateo, CA, pp. 92-101.", '111'
"Clouse, J., & Utgoff, P. 1992. A teaching method for reinforcement learning. Proc. 9th Intl. ML Conf., 92-101.", '111'
"Clouse, J. and P. Utgoff, A teaching method for reinforcement learning. In Proc. of the  Ninth International Workshop on Machine Learning, 1992.", '111'
"Clouse, J., & Utgoff, P. (1992). A teaching method for reinforcement learning. In Proceedings of the Ninth International Conference on Machine Learning, pp. 92-101 Aberdeen, Scotland.", '111'
"Clouse, J.A., & P.E. Utgoff, 1992. A teaching method for reinforcement learning. Proceedings of the Ninth Conference on Machine Learning, Aberdeen, Scotland, 92101.", '111'
"Clouse, J. A. & Utgoff, P. E. (1992). A Teaching Method for Reinforcement Learning. In Proceedings of the Ninth International Conference on Machine Learning. Ed. D. Sleeman, & P. Edwards. Morgan Kaufmann, 92-101.", '111'
"Clouse, J. and P. Utgoff, A teaching method for reinforcement learning. In Proc. of the Ninth International Workshop on Machine Learning, 1992.", '111'
"Schwartz, A. (1993), A reinforcement learning method for maximizing undiscounted rewards, in P. Utgoff, ed., Proceedings of the Tenth International Conference on Machine Learning, Morgan Kaufmann.", '114'
"Schwartz, A. (1993). A reinforcement learning method for maximizing undiscounted rewards. In Proceedings of the Tenth International Conference on Machine Learning, San Mateo, CA. Morgan Kaufmann.", '114'
"Schwartz, Anton 1993. A reinforcement learning method for maximizing undiscounted rewards. In Proceedings of the Tenth International Conference on Machine Learning, Amherst, Massachusetts. Morgan Kaufmann. 298305.", '114'
"Tan, M. 1993. Multi-agent reinforcement learning: independent vs. cooperative agents. In Proceedings of the Tenth International Conference on Machine Learning, Amherst, Massachusetts. Morgan Kaufmann.", '117'
"Ming Tan. Multiagent reinforcement learning: Independent vs. cooperative agents. In Proceedings of the Tenth International Conference on Machine Learning, pages 330337, 1993.", '117'
"Kaelbling, L. P. (1993). Hierarchical reinforcement learning: Preliminary results. In Proceedings of the Tenth International Conference on Machine Learning, (pp. 167-173) San Francisco, CA. Morgan Kaufmann.", '123'
"Chapman, D., & Kaelbling, L. P. (1991). Input generalization in delayed reinforcement learning: An algorithm and performance comparisons. In Proc. 12th IJCAI, pp. 726-731. Morgan Kaufmann.  Cormen, T. H., Leiserson, C. E., & Rivest, R. L.", '126'
"Chapman, D. and L. P. Kaelbling (1991). Input generalization in delayed reinforcement learning: An alogorithm and performance comparisons. In: Proc. of IJCAI-91. pp. 726-731.", '126'
"Chapman, D. & Kaelbling, L. 1991. Input generalization in delayed reinforcement learning: An algorithm and performance comparisons. In Proceedings of Twelfth International Joint Conference on Artificial Intelligence (pp. 726-731). San Mateo, CA: Morgan K", '126'
"David J. Chapman and Leslie Pack Kaelbling (1991). Input Generalization in Delayed Reinforcement Learning: An Algorithm and Performance Comparisons. Proc. of the Twelfth Intern. Conf. on Articial Intelligence, pp. 726 - 731.", '126'
"David Chapman and Leslie Pack Kaelbling. Learning from delayed reinforcement in a complex domain. In Proceedings of IJCAI, 1991.", '135'
"Chapman, D. and Kaelbing, L. P. (1991). Learning from delayed reinforcement in a complex domain. Technical report, Teleos Research.", '138'
"D. Chapman and L. P. Kaelbling. Learning from Delayed Reinforcement In a Complex Domain. Technical Report, Teleos Research, 1991.", '138'
"Peter J. Millington. Associative reinforcement learning for optimal control. Master's thesis, Massachusetts Institute of Technology, 1991. (also Charles Stark Draper Laboratory, Inc., Technical Report CSDL-T-1070).", '141'
"Millington, P. J. (1991). Associative reinforcement learning for optimal control. Unpublished master's thesis, Massachusetts Institute of Technology, Cambridge, MA.", '141'
"Sutton, R. (1991). Reinforcement learning architectures for animats. In Meyer, J. & Wilson, S., editors, From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior. MIT Press, Cambridge, MA.", '144'
"Sutton, R. 1991. Reinforcement learning architectures for animats. In Meyer, J., & Wilson, S., eds., From Animals to Animats. MIT Press.", '144'
"Sutton R. S., Reinforcement Learning Architectures for Animats, In: From Animals to Animats, Proceedings of the First International Conference on the Simulation of Adaptive Behavior, edited by Meyer J.-A. & Wilson S.W., MIT Press/Bradford Books, 199", '144'
"Sutton, R. S. (1991), Reinforcement Learning Architectures for Animats, in `First International Conference on Simulation of Adaptive Behavior', The MIT Press, Cambridge, MA.", '144'
"Sutton, R. (1991). Reinforcement learning architectures for animats. In Meyer, J., & Wilson, S. (Eds.), From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior, pp. 288-296. MIT Press, Cambridge, MA.", '144'
"Mark Ring. Two methods for hierarchy learning in reinforcement enviroments. In From Animals to Animats 2: Proceedings of the 2nd International Conference on Simulation of Adaptive Behaviour:. MIT Press, 1992.", '147'
"Long-Ji Lin and Tom M. Mitchell. Reinforcement learning with hidden states. In Proceedings of the Second International Conference on Simulation of Adaptive Behavior: From Animals to Animats, 1992.", '150'
"Long-Ji Lin and Tom M. Mitchell. Reinforcement learning with hidden states. In Proceedings of the Second International Conference on Simulation of Adaptive Behavior: From Animals to Animats, 1992.", '150'
"Littman, M. L. An optimization-based categorization of reinforcement learning environments. In In From Animals to Animats 2: Proceedings of the Second International Conference on Simulation of Adaptive Behavior (1992), J.-A. M. H. Roitblat and S. W.", '153'
"Littman M., An Optimization-Based Categorization of Reinforcement Learning Environments. In: From Animals to Animats 2, Proceedings of the Second International Conference on Simulation of Adaptive Behavior, edited by Meyer J.-A., Roitblat H.L. & Wil", '153'
"Humphrys, M. (1996). Action selection methods using reinforcement learning. In Maes, P., Mataric, M., Meyer, J.-A., Pollack, J., and Wilson, S. W., editors, From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Ad", '156'
"J. Zhao and J. Schmidhuber. Incremental self-improvement for life-time multi-agent reinforcement learning. In Pattie Maes, Maja Mataric, Jean-Arcady Meyer, Jordan Pollack, and Stewart W. Wilson, editors, From Animals to Animats 4: Proceedings of the", '159'
"Zhao, J. and Schmidhuber, J. (1996). Incremental self-improvement for life-time multi-agent reinforcement learning. In Maes, P., Mataric, M., Meyer, J.-A., Pollack, J., and Wilson, S. W., editors, From Animals to Animats 4: Proceedings of the Fourth Inte", '159'
"Jieyu Zhao Jurgen H. Schmidhuber. Incremental self-improvement for life-time multiagent reinforcement learning. In Pattie Maes, Maja J. Mataric, Jean-Arcady Meyer, Jordan Pollack, and Stewart W. Wilson, editors, From Animals to Animats: Proceedings", '159'
"Zhao, J. and Schmidhuber, J. (1996). Incremental self-improvement for life-time multi-agent reinforcement learning. In Maes, P., Mataric, M., Meyer, J.-A., Pollack, J., and Wilson, S. W., editors, From Animals to Animats 4: Proceedings of the Fourth Inte", '159'
"Jieyu Zhao and Juergen Schmidhuber. Incremental selfimprovement for lifelong multi agent reinforcement learning. In Fourth International Conference on Simulation of Adaptive Behavior, Cape Cod, USA, 1996.", '159'
"Digney, B. (1996). Emergent hierarchical control structures: Learning reactive/hierarchical relationships in reinforcement environments. In Maes, P., Mataric, M., Meyer, J.-A., Pollack, J., and Wilson, S. W., editors, From Animals to Animats 4: Proceedin", '162'
"Jurgen Schmidhuber. A general method for multiagent reinforcement learning in unrestricted envi ronments. In Adaptation, Coevolution and Learning in Multiagent Systems: Papers from the 1996 AAAI Spring Symposium, pages 8487, Menlo Park,CA, March 199", '165'
"Krose, B.J.A and J.W.M.van Dam (1992). Adaptive state space quantisation for reinforcement learning of collision-free navigation IEEE International Conference on Intelligent Robots and System", '171'
"Krose, B.J.A. and J.W.M. van Dam, Learning to avoid collision: a reinforcement learning paradigm for mobile robot navigation IFAC/IFIP/IMACS International Symposium on Artificial Intelligence in Real-Time Control, Delft, 1992.", '174'
"W. Zhang and T. Dietterich. A reinforcement learning approach to job-shop scheduling. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, 1995. (to appear).", '177'
"W. Zhang and T. Dietterich. A reinforcement learning approach to job-shop scheduling. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, 1995. (to appear).", '177'
"W. Zhang and T. G. Dietterich. A reinforcement learning approach to job-shop scheduling. In Proceedings of IJCAI-95, pages 1114-1120, 1995.", '177'
"Zhang, W., and Dietterich, T. G. (1995) A Reinforcement Learning Approach to Job Shop Scheduling, Proceedings of the IJCAI.", '177'
"Dietterich, T. G., & Flann, N. (1995). Explanationbased learning and reinforcement learning: A unifed view. In Proceedings of Machine Learning Conference.", '183'
"Jaakkola, T., Singh, S. P., & Jordan, M. I. (1995). Reinforcement learning with soft state aggregation. Advances in Neural Information Processing Systems 7 (pp. 361-368), MIT Press.", '189'
"Singh, S., Jaakkola, T., and Jordan, M. (1995). Reinforcement learning with soft state aggregation. In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, Advances in Neural Information Processing Systems 7, Cambridge, MA. The MIT Press.", '189'
"T. Jaakkola, S. P. Singh, and M. I. Jordan. Reinforcement learning algorithm for partially observable Markov decision problems. In G. Tesauro, D. S. Touretzky, and T. K. Leen, editors, Advances in Neural Information Processing Systems 7, pages 345-3", '192'
"Jaakkola, T., Singh, S. P., and Jordan, M. I. (1995). Reinforcement learning algorithm for partially observable Markov decision problems. In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, Advances in Neural Information Processing Systems 7, pag", '192'
"Jaakkola, T., Singh, S. P., and Jordan, M. I. (1995). Reinforcement learning algorithm for partially observable Markov decision problems. In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, Advances in Neural Information Processing Systems 7, pag", '192'
"T. Jaakkola, S.P. Singh, and M.I. Jordan. Reinforcement learning algorithm for partially observable Markov decision problems. In Advances in Neural Information Processing Systems 7. Morgan Kaufmann, 1995.", '192'
"Jaakkola, T., Singh, S. P., and Jordan, M. I. (1995). Reinforcement learning algorithm for partially observable Markov decision problems. In Tesauro, G., Touretzky, D. S., and Leen, T. K., editors, Advances in Neural Information Processing Systems 7, pag", '192'
"Satinder Pal Singh, Tommi Jaakkola, and Michael I. Jordan. Model-free reinforcement learning for non-markovian decision problems. In The Proceedings of the Eleventh International Machine Learning Conference. Morgan Kaufmann Publisher", '195'
"Satinder Pal Singh, Tommi Jaakkola, and Michael I. Jordan. Model-free reinforcement learning for non-Markovian decision problems. In Proceedings of the Eleventh International Conference on Machine Learning, pages 284-292, San Francisco, California,", '195'
"Singh, Satinder Pal; Jaakkola, Tommi; and Jordan, Michael I. 1994. Model-free reinforcement learning for non-markovian decision problems. In Proceedings of the Machine Learning Conference. To appear.", '195'
"Heger, Matthias 1994. Consideration of risk in reinforcement learning. In Proceedings of the Machine Learning Conference. To appear.", '201'
"Heger, M. (1994). Consideration of risk in reinforcement learning. In Proceedings of the Eleventh International Conference on Machine Learning, pages 105-111, San Francisco, CA. Morgan Kaufmann.", '201'
"T. Robinson and F. Fallside. Dynamic reinforcement driven error propagation networks with application to game playing. In Eleventh Annual Conference of the Cognitive Science Society, 1989.", '204'
"T. Robinson and F. Fallside. Dynamic reinforcement driven error propagation networks with application to game playing. In Proceedings of the 11th Conference of the Cognitive Science Society, Ann Arbor, pages 836-843, 1989.", '204'
"P. W. Munro. A dual back-propagation scheme for scalar reinforcement learning. Proceedings of the Ninth Annual Conference of the Cognitive Science Society, Seattle, WA, pages 165-176, 1987.", '207'
"pages 107-115.  [66] P. W. Munro. A dual back-propagation scheme for scalar reinforcement learning. In Proceedings of the Ninth Annual Conference of the Cognitive Science Society, Seattle, WA, 1987.", '207'
"S. D. Whitehead. A complexity analysis of cooperative mechanisms in reinforcement learning. In Proc. AAAI-91, pages 607-613, 1991.", '210'
"S.D. Whitehead, A complexity analysis of cooperative mechanisms in reinforcement learning, Proceeding of the Ninth National Conference on Artificial Intelligence (AAAI91), 607613, 1991.", '210'
"Whitehead, S.D. (1991). A complexity analysis of cooperative mechanisms in reinforcement learning. In: Proceedings of the 9th NIPS, AAAI Press, pp. 607613.", '210'
"Whitehead, S. 1991. A complexity analysis of cooperative mechanisms in reinforcement learning. AAAI-91, 607-613.", '210'
"Whitehead, S. D. (1991). A complexity analysis of cooperative mechanisms in reinforcement learning. In: Proc. AAAI-91. pp. 607-613.", '210'
"Whitehead,S.D. (1991b). A complexity analysis of cooperative mechansims in reinforcement learning.", '210'
"Whitehead, S. (1991), A complexity analysis of cooperative mechanisms in reinforcement learning, in AAAI-91: Proceedings of the Ninth National Conference on Artificial Intelligence, AAAI Press/MIT Press.", '210'
"Whitehead, S. (1991). A complexity analysis of cooperative mechanisms in reinforcement learning. In Proceedings of the Ninth National Conference on Artificial Intelligence, pp. 607613 Anaheim, CA.", '210'
"Whitehead, S. D., 1991a. A complexity analysis of cooperative mechanisms in reinforcement learning. Proceedings of the 9th National Conference on Artificial Intelligence, 607613.", '210'
"Mahadevan, S. and J. Connell, Automatic programming of behavior-based robots using reinforcement learning. In Proc. of the Ninth National Conference on Artificial Intelligence, 1991.", '213'
"Mahadevan, S. and J. Connell, Automatic programming of behavior-based robots using reinforcement learning. In Proc. of the Ninth National Conference on Artificial Intelligence, 1991.", '213'
"Mahadevan S. & Connell, J., Automatic Programming of Behavior-Based Robots using Reinforcement Learning, In: Proceedings of the Ninth National Conference on Artificial Intelligence, MIT Press, 1991.", '213'
"Mahadevan, S. and J. Connell, Automatic programming of behavior-based robots using reinforcement learning. In Proc. of the Ninth National Conference on Artificial Intelligence, 1991.", '213'
"Long-Ji Lin. Programming robots using reinforcement learning and teaching. AAAI, 1991.", '216'
"Lin, L., Programming robots using reinforcement learning and teaching. In Proc. of the Ninth National Conference on Artificial Intelligence, 1991.", '216'
"Lin, L.J. (1991). Programming robots using reinforcement learning and teaching. In: Proceedings of the AAAI91.", '216'
"Lin, L., Programming robots using reinforcement learning and teaching. In Proc. of the Ninth National Conference on Artificial Intelligence, 1991.", '216'
"Lin, L.-J. (1991). Programming Robots Using Reinforcement Learning and Teaching. In Proceedings of the Ninth National Conference on Artificial Intelligence. MIT Press, 781-786.", '216'
"Lin, L., Programming robots using reinforcement learning and teaching. In Proc. of the Ninth National Conference on Artificial Intelligence, 1991.", '216'
"Lin, L.J. (1991). Programming robots using reinforcement learning and teaching. In: 9th International Conference on Artificial Intelligence, AAA-91.", '216'
"Mahadevan, S., and Connell, J. 1992. Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence 55(2-3):189-208.", '222'
"Mahadevan, S. & Connell, J. (1992). Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence, 55:311-365.", '222'
"S. Mahadevan and J. Connell. Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence, 55:311-365, 1992.", '222'
"S. Mahadevan and J. Connell, Automatic programming of behavior-based robots using reinforcement learning, Artificial Intelligence, 55, 311365, (1992).", '222'
"Mahadevan, S., Connel, J. (1992). Automatic programming of behavior-based robots using reinforcement learning. In: Artificial Intelligence, vol. 55.", '222'
"Mahadevan, S., & Connell, J. 1992. Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence 55:311-365.", '222'
"Mahadevan, S., and Connell, J. 1992. Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence 55(2-3):189-208.", '222'
"Mahadevan, S., and Connell, J. (1992). Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence, 55, 2, 311365.", '222'
"Mahadevan, S. & Connell, J. (1992), Automatic programming of behavior-based robots using reinforcement learning, Artificial Intelligence 55(2-3), 311-365.", '222'
"Mahadevan, S., & Connell, J. (1992). Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence, 55, 311-365.", '222'
"S. Mahedevan and J. Connell (1991). Automatic programming of behavior-based robots using reinforcement learning. Articial Intelligence. Vol 55, pp. 311-365. Elsevier.", '222'
"Mahadevan, S., and Connell, J. (1992). Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence, 55, pp.311-365.", '222'
"Mahadevan, S., & J. Connell, 1992. Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence , 55, 2, 311365. Millan, J. del R., this volume. Reinforcement learning of goal-directed obstacle-avoiding reaction st", '222'
"Mahadevan, S. and Connell, J. (1992). Automatic programming of behavior-based robots using reinforcement learning. Artificial Intelligence, 55, 2, 311365.", '222'
"Sridhar Mahadevan and Jonathan Connell. Automatic programming of behavior-based robots using reinforcement learning. Research Report RC 16359, IBM T.J. Watson Research Center, December 1990.", '225'
"S. Mahadevan and J. Connell. Automatic programming of behavior-based robots using reinforcement learning. Technical report, IBM T. J. Watson Research Center, NY 10598, 1990.", '225'
"Sridhar Mahadevan and Jonathan Connell. Scaling reinforcement learning to robotics by exploiting the subsumption architecture. In Proceedings of Machine Learning Workshop '91, July 1991.", '228'
"Sridhar Mahadevan and Jonathan Connell. Scaling reinforcement learning to robotics by exploiting the subsumption architecture. In Proceedings of the Eighth International Workshop on Machine Learning, 1991.", '228'
"Lambert Wixson. Scaling reinforcement learning techniques via modularity. In Proceedings of the Eight International Workshop on Machine Learning, pages 368-372. Morgan Kaufmann, 1991.", '231'
"Lambert E. Wixson, Scaling Reinforcement Learning Techniques via Modularity, In Proceedings of the Eighth International Workshop on Machine Learning, June 1991.", '231'
"Wixson, L. E. (1991). Scaling reinforcement learning techniques via modularity. In Birnbaum, L. A. and Collins, G. C., editors, Machine Learning: Proceedings of the Eighth International Workshop (ML91), pages 368-372. Morgan Kaufmann Publishers.", '231'
"H. R. Berenji, Refinement of Approximate Reasoning-Based Controllers by Reinforcement Learning, in: Proceedings of the Eighth International Machine Learning Workshop, Evanston, IL (1991), 475479.", '234'
"Berenji, H. R. (1991). Refinement of approximate reasoning-based controllers by reinforcement learning. Proceedings of the Eighth International Machine Learning Workshop (pp. 475-479). Evanston, IL: Morgan Kaufmann.", '234'
"Long Ji Lin. Self-improvment based on reinforcement learning, planning, and teaching. In Proceedings of the Eighth International Workshop on Machine Learning, 1991.", '237'
"Long-Ji Lin. Self-improving based on reinforcement learning, planning, and teaching. In Proceedings of the Eighth International Workshop on Machine Learning, Evanston, Illinois, 1991. Morgan Kaufmann.", '237'
"Lin, L.-J. (1992). Self-improving reactive agents based on reinforcement learning, planning, and teaching. Machine Learning, 8(3):293-321.", '240'
"Lin, L. (1992). Self-improving reactive agents based on reinforcement learning, planning, and teaching. Machine Learning, 8:293-321.", '240'
"L-J. Lin, Self-improving reactive agents based on reinforcement learning, planning and teaching, Machine Learning, 8, 293322, (1992).", '240'
"Lin, L.J. (1992). Self-improving reactive agents based on reinforcement learning, planning and teaching. In: Machine Learning, 8, pp. 293-321.", '240'
"Lin, L. 1992. Self-improving reactive agents based on reinforcement learning, planning, and teaching. Machine Learning 8:293-321.", '240'
"Lin, L. (1992). Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching. Machine Learning, 8, 293-321.", '240'
"Lin, L. 1992. Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching. Machine Learning, 8, 293-321.", '240'
"Lin, L. (1992). Self-improving reactive agents based on reinforcement learning, planning, and teaching. Machine Learning, 8, 293-321.", '240'
"Long-Li Lin (1992). Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching. Machine Learning 8, pp. 293-321. Boston, MA: Kluwer Academic.", '240'
"L-J Lin. Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine Learning, 8:293-321, 1992.", '240'
"Lin, L-J., 1992. Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine Learning , 8, 3-4, 293322.", '240'
"Lin, L-J. (1992). Self-improving reactive agents based on reinforcement learning, planning and teaching. Machine Learning, 8, 3-4, 293322.", '240'
"Longji Lin. Self-improving reactive agents based on reinforcement learning, planning and teaching. machine learning, 8:293-321, 1992.", '240'
"J. H. Schmidhuber. An on-line algorithm for dynamic reinforcement learning and planning in reactive environments. In Proc. IEEE/INNS International Joint Conference on Neural Networks, San Diego, volume 2, pages 253-258, 1990.", '246'
"Williams, R. J. (1988). On the use of backpropagation in associative reinforcement learning. In Proceedings of the IEEE International Conference on Neural Networks San Diego, California.", '249'
"R. J. Williams. On the use of backpropagation in associative reinforcement learning. In IEEE International Conference on Neural Networks, San Diego, volume 2, pages 263-270, 1988.", '249'
"Lonnie Chrisman. Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In AAAI-92, 1992.", '252'
"L. Chrisman. Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proceedings of the Tenth International Conference on Artificial Intelligence, pages 183-188. AAAI Press, San Jose, California, 1992.", '252'
"Lonnie Chrisman. Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In AAAI-92, 1992.", '252'
"Chrisman, L. (1992). Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proc. Tenth National Conference on AI (AAAI).", '252'
"Chrisman, L. 1992. Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proceedings of the Tenth National Conference on Artificial Intelligence, 183-188. San Jose, California: AAAI Press.", '252'
"Chrisman, L. (1992). Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proceedings of the Tenth International Conference on Artificial Intelligence, pages 183-188. AAAI Press, San Jose, California.", '252'
"Chrisman, L. (1992). Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proceedings of the Tenth International Conference on Artificial Intelligence, pages 183-188. AAAI Press, San Jose, California.", '252'
"Lonnie Chrisman. Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proceedings of the Tenth National Conference on Artificial Intelligence, pages 183-188, San Jose, California, 1992. AAAI Press.  31", '252'
"Chrisman, L. (1992). Reinforcement learning with perceptual aliasing: The perceptual distinctions approach. In Proceedings of the Tenth International Conference on Artificial Intelligence, pages 183-188. AAAI Press, San Jose, California.", '252'
"S. Koenig and R.G. Simmons. Complexity Analysis of Reinforcement Learning. In Proceedings of the Eleventh International Conference on Artificial Intelligence (AAAI-93). MIT Press, 1993.", '255'
"Koenig, S. and Simmons, R. G. (1996). The effect of representation and knowedge on goal-directed exploration with reinforcement learnign algorithm. Machine Learning, 22:228-250.", '261'
"S. Mahadevan, Average Reward Reinforcement Learning: Foundations, Algorithms, and Empirical Results, Machine Learning, Special Issue on Reinforcement Learning (edited by Leslie Kaebling), vol. 22, pp. 159-196, 1996.", '264'
"Mahadevan, S. (1996). Average reward reinforcement learning: Foundations, algorithms, and empirical results. Machine Learning, 22(1/2/3):159-196.", '264'
"McCallum, R. A. Hidden state and reinforcement learning with instance-based state identification. IEEE Transations on Systems, Man and Cybernetics - Part B (Special issue on Learning Autonomous Robots) 26, 3 (1996).", '267'
"R.S. Sutton. (ed.), Machine Learning, 8(3/4), Special Issue on Reinforcement Learning, 1992.", '270'
"J. del R. Millan, Building Reactive Path-Finders through Reinforcement Connectionist Learning: Three Issues and An Architecture. Proc. 10th European Conf on AI, Vienna Austria, 1992.", '273'
"J. del R. Millan, Building Reactive Path-Finders through Reinforcement Connectionist Learning: Three Issues and An Architecture. Proc. 10th European Conf on AI, Vienna Austria, 1992.", '273'
"Millan, J. del R., & C. Torras, 1992. A reinforcement connectionist approach to robot path finding in non maze-like environments. Machine Learning , 8, 3-4, 363395.", '276'
"J. del R. Millan, C. Torras, A reinforcement connectionist approach to robot path finding in non-maze-like environments, Machine Learning 8, pp. 363-395, 1992.", '276'
"Whitehead, S. D., & D. H. Ballard, 1991. Learning to perceive and act by trial and error. Machine Learning , 7, 1, 4583. Whitehead, S. D., & L. J. Lin, this volume. Reinforcement learning in non-Markov environments.", '279'
"J. Schmidhuber. Reinforcement learning in Markovian and non-Markovian environments. In D. S. Lippman, J. E. Moody, and D. S. Touretzky, editors, Advances in Neural Information Processing Systems 3, pages 500-506. San Mateo, CA: Morgan Kaufmann, 1991", '282'
"J. H. Schmidhuber. Reinforcement learning in markovian and non-markovian environments. In D. Touretzky and D. S. Lippman, editors, Advances in Neural Information Processing Systems 3, in press. San Mateo, CA: Morgan Kaufmann, 1991.", '282'
"Schmidhuber, J. (1991). Reinforcement learning in Markovian and non-Markovian environments. In Lippman, D. S., Moody, J. E., and Touretzky, D. S., editors, Advances in Neural Information Processing Systems 3, pages 500-506. San Mateo, CA: Morgan Kaufmann", '282'
"Schmidhuber, J. (1991). Reinforcement learning in Markovian and non-Markovian environments. In Lippman, D. S., Moody, J. E., and Touretzky, D. S., editors, Advances in Neural Information Processing Systems 3, pages 500-506. San Mateo, CA: Morgan Kaufmann", '282'
"Schmidhuber, J. (1991c). Reinforcement learning in Markovian and non-Markovian environments. In Lippman, D. S., Moody, J. E., and Touretzky, D. S., editors, Advances in Neural Information Processing Systems 3, pages 500-506. San Mateo, CA: Morgan Kaufman", '282'
"Dayan, P. and Hinton, G. (1993). Feudal reinforcement learning. In Hanson, S. J., Cowan, J. D., and Giles, C. L., editors, Advances in Neural Information Processing Systems 5. Morgan Kaufmann Publishers, San Mateo, CA.", '285'
"P. Dayan and G. E. Hinton. Feudal Reinforcement Learning. In S. J. Hanson, J. D Cowan, and C. L. Giles, editors, Advances in Neural Information Processing Systems 5. Morgan Kaufmann, 1993.  36 A.W. MOORE AND C.G. ATKESON", '285'
"Dayan, P., & Hinton, G. E. (1993). Feudal reinforcement learning. Advances in Neural Information Processing Systems, 5.", '285'
"Dayan, P. and Hinton, G. (1993). Feudal reinforcement learning. In Lippman, D. S., Moody, J. E., and Touretzky, D. S., editors, Advances in Neural Information Processing Systems 5, pages 271-278. San Mateo, CA: Morgan Kaufmann.", '285'
"Dayan, P., & Hinton, G. (1993). Feudal reinforcement learning. In Adv. in Neural Info. Proc. Sys., 5. (pp. 271-278) Morgan Kaufmann, San Francisco, CA.", '285'
"Bradtke, S.J. (1993). Reinforcement learning applied to linear quadratic regulation. In: Advances of Neural Information Processing 5, Morgan Kaufmann, pp. 295-302.  Breiman, L., Friedman, J.H., Ohlsen, R.A., Stone, C.J.", '291'
"Bradtke, S. J (1993). Reinforcement learning applied to linear quadratic regulation. Proceedings of the Fifth Conference on Neural Information Processing Systems (pp. 295-302). Morgan Kaufmann.", '291'
"Bradtke, S. J. (1993). Reinforcement Learning Applied to Linear Quadratic Regulation. Proceedings of the 5th annual Conference on Neural Information Processing Systems .", '291'
"Bradtke, S. J. (1993). Reinforcement learing applied to linear quadratic regulation. In: S. J. Hanson, J. D. Cowan, & C. L. Giles (Eds.) Advances in Neural Information Processing Systems 5. San Mateo, CA: Morgan Kaufmann.", '291'
"S. J. Bradtke. Reinforcement learning applied to linear quadratic regulation. In Advances in Neural Information Processing Systems 5, pages 295302, San Mateo, CA, 1993. Morgan Kaufmann.", '291'
"S. J. Bradtke. Reinforcement learning applied to linear quadratic regulation. In S. J. Hanson, J. Cowan, and C. L. Giles, editors, NIPS-5. Morgan Kaufmann, 1993.", '291'
"Moore, A. W. & Atkeson, C. G. (1993). Memory-based reinforcement learning: Converging with less data and less real time. In: S. J. Hanson, J. D. Cowan, & C. L. Giles (Eds.) Advances in Neural Information Processing Systems 5. San Mateo, CA: Morgan Kaufma", '300'
"Moore, A. W. & Atkeson, C. G., (1992) Memory-based reinforcement learning: Converging with less data and less real time, In: S. J. Hanson, J. D. Cowan, & C. L. Giles (Eds.) Advances in Neural Information Processing Systems 5. San Mateo, CA: Morgan Kaufma", '300'
"Moore, Andrew W. and Atkeson, Christopher G. 1993. Memory-based reinforcement learning: Efficient computation with prioritized sweeping. In Advances in Neural Information Processing 5, San Mateo, California. Morgan Kaufmann.", '303'
"Moore, A. W. (1994). The partigame algorithm for variable resolution reinforcement learning in multidimensional state-spaces. In Neural Information Processing Systems 6, pages 711-718. Morgan Kaufmann Publishers, San Mateo, CA.", '306'
"Moore, A. W. (1994). The parti-game algorithm for variable resolution reinforcement learning in multidimensional state spaces. In Advances in Neural Information Processing Systems 6, San Mateo, CA. Morgan Kaufmann.", '306'
"Moore, A. W. (1993). The partigame algorithm for variable resolution reinforcement learning in multidimensional statespaces.. submitted to NIPS 93.", '306'
"Moore, A. W. and Atkeson, C. G. (1995). The parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces. Machine Learning, 21, 119-223.", '309'
"A. W. Moore and C. G. Atkeson. The Parti-game Algorithm for Variable  Resolution Reinforcement Learning in Multidimensional State-spaces. Machine Learning, 21, 1995.", '309'
"Moore, A. W. & Atkeson, C. G. (1995). The Parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces, Machine Learning, 21.", '309'
"A. W. Moore. The parti-game algorithm for variable resolution reinforcement learning in multidimensional state spaces. In S. J. Hanson, J. D. Cowan, and C. L. Giles, editors, Advances in Neural Information Processing Systems, volume 6. Morgan Kaufmann, 1", '309'
"A. W. Moore and C. G. Atkeson. The Parti-game Algorithm for Variable Resolution Reinforcement Learning in Multidimensional State-spaces. Machine Learning, 21, 1995.", '309'
"J. A. Boyan and A. W. Moore. Generalization in reinforcement learning: Safely approximating the value function. In G. Tesauro, D. S. Touretzky, and T. K. Leen, editors, Advances in Neural Information Processing Systems 7. MIT Pres", '315'
"J. A. Boyan and A. W. Moore. Generalization in Reinforcement Learning: Safely Approximating the Value Function. In Neural Information Processing Systems 7, 1995.", '315'
"J. A. Boyan and A. W. Moore. Generalization in reinforcement learning: safely approximating the value function. In Advances in Neural Information Processing Systems 7, San Mateo, CA, 1995. Morgan Kaufmann.", '315'
"J.A. Boyan and A.W. Moore. Generalization in reinforcement learning: Safely approximating the value  function. In Advances in Neural Information Processing Systems 7. Morgan Kaufmann, 1995.", '315'
"J. A. Boyan and A. W. Moore. Generalization in reinforcement learning: safely approximating the value function. In G. Tesauro and D. Touretzky, editors, Advances in Neural Information Processing Systems, volume 7. Morgan Kaufmann, 1995.", '315'
"J. A. Boyan and A. W. Moore. Generalization in reinforcement learning: safely approximating the value function. In Advances in Neural Information Processing Systems 6, San Mateo, CA, 1995. Morgan Kaufmann.", '315'
"J. A. Boyan and A. W. Moore. Generalization in reinforcement learning: Safely approximating the value function. In G. Tesauro, D. S. Touretzky, and T. K. Leen, editors, Advances In Neural Information Processing Systems 7. MIT Pres", '315'
"R. S. Sutton. Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Neural Information Processing Systems 8, 1996.", '318'
"R. S. Sutton. Generalization in reinforcement learning: Successful examples using sparse coarse coding. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems, volume 8. MIT Press, 1996.", '318'
"R.S. Sutton. Generalization in reinforcement learning: Successful examples using sparse coarse coding. To Appear in: Advances in Neural Information Processing Systems 8. MIT Press, 1996.", '318'
"R. S. Sutton. Generalization in Reinforcement Learning: Successful Examples Using Sparse Coarse Coding. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Neural Information Processing Systems 8, 1996.", '318'
"Crites R.H., Barto A.G. (1995), Improving elevator performance using reinforcement learning. Proceedings of 8th Neural Information Processing Systems Conference, Denver, Colorado.", '321'
"R. Crites and A. Barto. Improving elevator performance using reinforcement learning. In D. Touretzky, M. Mozer, and M. Hasselno, editors, Advances in Neural Information Processing Systems 8, 1996.", '321'
"R.H. Crites and A.G. Barto. Improving elevator performance using reinforcement learning. In D.S. Touretzky, M.C. Mozer, and M.E. Hasselmo, editors, Advances in Neural Information Processing Systems 8, pages 1017-1023, Cambridge MA, 1996. MIT Press.", '321'
"R. H. Crites and A. G. Barto. Improving Elevator Performance using Reinforcement Learning. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Neural Information Processing Systems 8, 1996.", '321'
"Crites, R. H., and Barto, A. G. (1996). Improving elevator performance using reinforcement learning. To appear in Advances in Neural Information Processing Systems 8, D. S. Touretzky, M. C. Mozer, M. E. Hasselmo, eds., MIT Press.", '321'
"R. Crites and A. Barto. Improving elevator performance using reinforcement learning. In D. Touretzky, M. Mozer, and M. Hasselno, editors, Advances in Neural Information Processing Systems 8, 1996.", '321'
"Crites, R. H., and Barto, A. G (1996) Improving Elevator Performance Using Reinforcement Learning, Advances in Neural Information Processing Systems 8, Touretzky, D. S., Mozer, M. C., and Hasselmo, M. E., eds., MIT Press, Cambridge, MA.", '321'
"Crites, R. H. & Barto, A. G. (1996). Improving elevator performance using reinforcement learning. In Touretzky, D., Mozer, M., & Hasselmo, M., editors, Advances in Neural Information Processing Systems (volume 8). MIT Press, Cambridge, MA.", '321'
"G. J. Gordon. Stable fitted reinforcement learning. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Advances in Neural Information Processing Systems, volume 8. MIT Press, 1996.", '324'
"S. Davies. Multidimensional Triangulation and Interpolation for Reinforcement Learning. In Neural Information Processing Systems 9, 1996. Morgan Kaufmann, 1997.", '327'
"S. Davies. Applying grid-based interpolation to reinforcement learning. In submitted Neural Information Processing Systems 9, 1996.", '330'
"H. Chung and C. Chiang, A Self-Learning and Tuning Fuzzy Logic Controller Employing Reinforcement Learning. article submitted to MITA Press, May 1994.", '333'
"Dorigo M. and L.M. Gambardella, 1995. Ant-Q: A Reinforcement Learning Approach to Combinatorial Optimization. Tech. Rep. IRIDIA/95-01, Universit Libre de Bruxelles, Belgium.", '336'
"P. Cichosz, Truncating Temporal Differences: On the Efficient Implementation of TD(lambda) for Reinforcement Learning, Journal of Artificial Intelligence Research, no. 2, pp. 286-318, 1995.", '339'
"P. Cichosz. Truncating temporal differences: On the efficient implementation of TD(>=) for reinforcement learning. JAIR, 2:287-318, 1995.", '339'
"Ming Tan. Cost sensitive reinforcement learning for adaptive classification and control. In AAAI, 1991.", '342'
"Tan, M. 1991. Cost-sensitive reinforcement learning for adaptive classification and control. In Proceedings of the Ninth National Conference on Artificial Intelligence.", '342'
"Lin, L. (1993). Scaling up reinforcement learning for robot control. In Machine Learning: Proceedings on the Tenth International Conference, (pp. 182-189), Amherst, MA.", '345'
"Lin, L. 1993. Scaling up reinforcement learning for robot control. Proc. 10th Intl. ML Conf., 182-189.", '345'
"Lin, L. (1993). Scaling up reinforcement learning for robot control. In Proceedings of the Tenth International Conference on Machine Learning, pp. 182-189 Amherst, MA.", '345'
"Lin, L-J. (1993b). Scaling up reinforcement learning for robot control. Proceedings of the Tenth International Conference on Machine Learning, Morgan Kaufmann, 182189.", '345'
"S.D. Whitehead and D. H. Ballard. Active perception and reinforcement learning. Neural Computation, 2(4):409-419, 1990.", '348'
"Whitehead S. & Ballard D., Active Perception and Reinforcement Learning, In: Proceedings of the Seventh International Conference on Machine Learning, Austin, Texas, 1990.", '348'
"Whitehead, S. and Ballard, D. H. (1990). Active perception and reinforcement learning. Neural Computation, 2(4):409-419.", '348'
"M. L. Littman and C. Szepesvari. A generalized reinforcement-learning model: Convergence and applications. In L. Saitta, editor, Machine Learning: Proceedings Of The Thirteenth International Conference (this volume). Morgan", '351'
"M. L. Littman and C. Szepesvari. A generalized reinforcement-learning model: Convergence and applications. In L. Saitta, editor, Machine Learning: Proceedings of the Thirteenth International Conference. Morgan Kaufmann, 199", '351'
"Whitley, D., Dominic, S. and Das, R. (1991). Genetic Reinforcement Learning with Multilayer Neural Networks. Proceedings of the Fourth International Conference on Genetic Algorithms, pp. 562-569. Morgan Kaufmann.", '354'
"D. Whitley, S. Dominic, and R. Das. Genetic reinforcement learning with multilayer neural networks. In Proceedings of the Fourth International Conference on Genetic Algorithms, pages 562-569. Morgan Kaufmann, 1991.", '354'
"J. H. Schmidhuber. Reinforcement learning with interacting continually running fully recurrent networks. In Proc. INNC International Neural Network Conference, Paris, volume 2, pages 817820, 1990.", '357'
"Storck, J., Hochreiter, S., and Schmidhuber, J. (1995). Reinforcement driven information acquisition in nondeterministic environments. In Proceedings of the International Conference on Artificial Neural Networks, volume 2, pages 159-164. EC2 & Cie, Paris", '360'
"Graham, D. P. W. and D'Eleuterio, G. M. T. (1994). CMAC Manipulator Control Using a Reinforcement Learned Trajectory Planner In Marinaro, M. and Morasso, P. G.(Hrsg.), Proceedings of the International Conference on Artificial Neural Networks (ICANN-94),", '363'
"R. Maclin and J. Shavlik, Incorporating advice into agents that learn from reinforcements, in Proceedings of the Twelfth National Conference on Artificial Intelligence, (Seattle, WA), pp. 694-699, AAAI/MIT Press, 1994.", '369'
"Maclin, R., & Shavlik, J. (1994). Incorporating advice into agents that learn from reinforcements. In Proceedings of the Twelfth National Conference on Artificial Intelligence, pp. 694-699 Seattle, WA.", '369'
"Maclin, R., & Shavlik, J. 1994. Incorporating advice into agents that learn from reinforcements. Technical Report 1227, CS Dept., Univ. of Wisconsin-Madison.", '372'
"Sebastian B. Thrun. Efficient exploration in reinforcement learning.  Technical Report CMU-CS-92-102, CMU Comp. Sci. Dept., January 1992.", '378'
"S.B. Thrun, Efficient exploration in reinforcement learning, Technical Report CMUCS-92-102, Carnegie Mellon University, Pittsburgh, PA 15213, USA, 1992.", '378'
"Sebastian B. Thrun. Efficient exploration in reinforcement learning. Technical Report CMU-CS92-102, School of Computer Science, Carnegie Mellon University, 1992.", '378'
"S. Thrun. Efficient exploration in reinforcement learning. Technical Report CMUCS-92-102, Carnegie Mellon University, March 1992.", '378'
"Thrun, S. (1992), Efficient exploration in reinforcement learning, Technical Report CMU-CS-92-102, CMU School of Computer Science.", '378'
"Thrun, S. (1992). Efficient exploration in reinforcement learning. Technical Report CMU-CS-92102, Carnegie-Mellon University.", '378'
"R. J. Williams. Toward a theory of reinforcement-learning connectionist systems. Technical Report NU-CCS-88-3, College of Comp. Sci., Northeastern University, Boston, MA, 1988.", '381'
"R. J. Williams. Toward a theory of reinforcement-learning connectionist systems. Technical Report NU-CCS-88-3, College of Comp. Sci., Northeastern University, Boston, MA, 1988.", '381'
"Goldberg, D. E. (1988). Probability matching, the magnitude of reinforcement, and classifier system bidding. (TCGA Report No. 88002). Tuscaloosa: University of Alabama, Department of Engineering Mechanics.", '384'
"Tham, C. K. and Prager, R. W. (1993). Reinforcement learning methods for multi-linked manipulator obstacle avoidance and control Technischer Bericht, Cambridge University Engineering Department, Trumpington Street, Cambridge CB2 1PZ, UK.", '387'
"Thrun, S. & Schwartz, A. (1993) Issues in using function approximation for reinforcement learning. Proceedings of the Fourth Connectionist Models Summer School. Hillsdale, NJ: Erlbaum.", '390'
"S. Thrun and A. Schwartz. Issues in using approximation for reinforcement learning. In Proceedings of the Fourth Connectionist Models Summer School, Hillsdale, NJ, 1993. Lawrence Erlbaum Publisher.", '390'
"S. Thrun and A. Schwartz. Issues in using function approximation for reinforcement learning. In Proceedings of the Fourth Connectionist Models Summer School, Hillsdale, NJ, 1993. Lawrence Erlbaum.", '390'
"S. Thrun and A. Schwartz. Issues in using function approximation for reinforcement learning. In Proceedings of the Fourth Connectionist Models Summer School, 1993.", '390'
"S. Thrun and A. Schwartz. Issues in using function approximation for reinforcement learning. In Proceedings of the Fourth Connectionist Models Summer School, 1993.", '390'
"Tham, C. (1995). Reinforcement learning of multiple tasks using a hierarchical CMAC architecture. Robotics and Autonomous Systems, 15(4):247-274.", '396'
"Gullapalli V. (1995), Skillful control under uncertainty via direct reinforcement learning. Robotics and Autonomous Systems, Vol 15, pp 237-246.", '399'
"Gerhard Wei. Distributed reinforcement learning. Robotics and Autonomous Systems, 15:135142, 1995.", '402'
"G. Weiss, Multi-agent reinforcement learning, appears in: L. Steels, ed., The Biology and Technology of Intelligent Autonomous Agents (Springer, Berlin, 1994).", '405'
"M. B. Ring. Continual Learning in Reinforcement Environments. PhD thesis, University of Texas at Austin, Austin, Texas 78712, August 1994.", '408'
"Ring, M. B. (1994). Continual Learning in Reinforcement Environments. PhD thesis, University of Texas at Austin, Austin, Texas 78712.", '408'
"Ring, M. B. (1995). Continual Learning in Reinforcement Environments. R. Oldenbourg Verlag, Munchen, Wien.", '408'
"Ring, M. B. (1994). Continual Learning in Reinforcement Environments. PhD thesis, University of Texas at Austin, Austin, Texas.", '408'
"Marvin L. Minsky. Theory of neural-analog reinforcement systems and its application to the brain-model problem. PhD thesis, Princeton University, 1954.", '411'
"Werbos, P. J. (1990). Consistency of HDP Applied to a Simple Reinforcement Learning Problem. Neural Networks 3, 179-189.", '414'
"Werbos, P. J. (1990). Consistency of HDP applied to a simple reinforcement learning problem.", '414'
"Gullapalli, V. (1990). A stochastic reinforcement learning algorithm for learning real valued functions. Neural Networks 3, 671-692.", '417'
"M. Wiering and J. Schmidhuber. HQ-Learning: Discovering Markovian subgoals for non-Markovian reinforcement learning. Technical Report IDSIA-95-96, IDSIA, 1996.", '420'
"Wiering, M. A. and Schmidhuber, J. (1996a). HQ-Learning: Discovering Markovian subgoals for non-Markovian reinforcement learning. Technical Report IDSIA-96-96, IDSIA.", '420'
"Szepesvari, C. and Littman, M. L. (1996). Generalized Markov decision processes: Dynamicprogramming and reinforcement-learning algorithms. Technical Report CS-96-11, Brown University, Providence, RI.", '423'
"Kaelbling, L. P., Littman, M. L., and Moore, A. W. Reinforcement learning: A survey. Journal of Artificial Intelligence Research 4 (1996).", '426'
"Leslie P. Kaebling, Michael L. Littmann, and Andrew W. Moore. Reinforcement learning: A survey. Journal of Artificial Intelligence Research, 4, 1996.", '426'
"Kaelbling, L. P., Littman, M. L., & Moore, A. W. (1996). Reinforcement Learning: A Survey. Journal of Artificial Intelligence Research, 4, 237-285.", '426'
"Leslie Pack Kaelbling, Michael L. Littman, and Andrew W. Moore. Reinforcement learning: A survey. Journal of Articial Intelligence Research, 4:237285, May 1996.", '426'
"L. P. Kaelbling, M. L. Littman, and A. W. Moore. Reinforcement learning: A survey. Jornal of Artificial Intelligence Research, 4:237-285, 1996.", '426'
"Ok, D., & Tadepalli, P. (1996). Auto-exploratory average reward reinforcement learning. In Proceedings of AAAI-96.", '432'
"Satinder P. Singh. Reinforcement learning with a hierarchy of abstract models. In AAAI-92, 1992.", '435'
"S.P. Singh and R.S. Sutton. Reinforcement learning with replacing eligibility traces. To Appear In: Machine Learning, 1996.", '438'
"David E. Moriarty and Risto Miikkulainen. Efficient reinforcement learning through symbiotic evolution. Machine Learning, 22:11-32, 1996.", '441'
"Moriarty, D. E. and R. Miikkulainen (1996). Efficient reinforcement learning through symbiotic evolution. Machine Learning 22 (1). In Press.", '441'
"Moriarty, D. E. and R. Miikkulainen (1996). Efficient reinforcement learning through symbiotic evolution. Machine Learning 22 (1). In Press.", '441'
"R. Maclin and J. Shavlik, Creating advice-taking reinforcement learners, Machine Learning, vol. 22, pp. 251281, 1995.", '444'
"R. Maclin and Jude W. Shavlik. Creating advicetaking reinforcement learners. Machine Learning, 22(13):251281, 1996.", '444'
"R. Maclin and J.W. Shavlik. Creating advice-taking reinforcement learners. Machine Learning, 22(1-3), 1996.", '444'
"Whitley, D., Dominic, S., Das, R., and Anderson, C. W. (1993). Genetic reinforcement learning for neurocontrol problems. Machine Learning, 13:259-284.", '447'
"Whitley, D., Dominic, S., Das, R., and Anderson, C. (1993). Genetic Reinforcement Learning for Neurocontrol Problems. Machine Learning, 13:259-284.", '447'
"Whitley, D., Dominic, S., Das, R., and Anderson, C. W. (1993). Genetic reinforcement learning for neurocontrol problems. Machine Learning, 13:259-284.", '447'
"Whitley, D., S. Dominic, R. Das, C. Anderson (1993). Genetic reinforcement learning for neurocontrol problems. Machine Learning 13(2/3), 259-284.", '447'
"Whitley, D., S. Dominic, R. Das, C. Anderson (1993). Genetic reinforcement learning for neurocontrol problems. Machine Learning 13(2/3), 259-284.", '447'
"Whitley, D., S. Dominic, R. Das, C. Anderson (1993). Genetic reinforcement learning for neurocontrol problems. Machine Learning 13(2/3), 259-284.", '447'
"A. W. Moore and C. G. Atkeson. Prioritized Sweeping: Reinforcement Learning with Less Data and Less Real Time. Machine Learning, 13, 1993.", '450'
"A. W. Moore and C. G. Atkeson. Prioritized Sweeping: Reinforcement Learning with Less Data and Less Real Time. Machine Learning, 13, 1993.", '450'
"A. Moore and C. Atkeson. Prioritized sweeping: Reinforcement learning with less data and less real time. Machine Learning, 13(1):103-130, 1993.", '450'
"Moore, A. W. and Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning with less data and less real time. Machine Learning, 13.", '450'
"A. W. Moore and C. G. Atkeson. Prioritized Sweeping: Reinforcement Learning with Less Data and Less Real Time. Machine Learning, 13, 1993.", '450'
"Moore, A. and Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning with less data and less time. Machine Learning, 13:103-130.", '450'
"Kaelbling, L. P. (1993a). Associative reinforcement learning: Functions in kDNF. Machine Learning. To appear.", '453'
"Kaelbling, L. P. (1993a). Associative reinforcement learning: A generate and test algorithm. Machine Learning. To appear.", '453'
"Schmidhuber, J., Zhao, J., and Schraudolph, N. (1997a). Reinforcement learning with selfmodifying policies. In Thrun, S. and Pratt, L., editors, Learning to learn. Kluwer. in press.", '456'
"Schmidhuber, J., Zhao, J., and Schraudolph, N. (1997a). Reinforcement learning with selfmodifying policies. In Thrun, S. and Pratt, L., editors, Learning to learn. Kluwer. in press.", '456'
"Harmon, M. E., Baird, L. C., & Klopf, A. H. (1996). Reinforcement learning applied to a differential game. Adaptive Behavior, 4(1), 3-28.", '459'
"Robert Levinson, General Game-Playing and Reinforcement Learning. UCSC-CRL-9506. University of California, Santa Cruz.", '462'
"Szepesvari, C. (1995). General framework for reinforcement learning. In Proceedings of ICANN'95 Paris.", '465'
"Lin, L-J. (1993a). Hierarchical learning of robot skills by reinforcement. Proceedings of", '468'
"Gullapalli, V., J. A. Franklin and H. Benbrahim (1994). Acquiring robot skills via reinforcement learning. IEEE Control Systems Magazine 14(1), 13 - 24.", '471'
"Gullapalli, V., J. A. Franklin and H. Benbrahim (1994). Acquiring robot skills via reinforcement learning. IEEE Control Systems Magazine 14(1), 13 - 24.", '471'
"Roger Ford, Craig Boutilier, and Keiji Kanazawa. Exploiting natural structure in reinforcement learning: Experience in robot soccerplaying, 1994. Unpublished Manuscript.", '474'
"A.G. Barto and M. Duff. Monte Carlo matrix inversion and reinforcement learning. In D.S.Touretsky, ed., Advances in Neural Information Processing Systems 6. Morgan Kaufmann, 1994.", '477'
"S. Sathya Keerthi and B. Ravindran. A tutorial survey of reinforcement learning. Sadhana, 19(6):851-889, 1994.", '480'
"M. J. Mataric, A Comparative Analysis of Reinforcement Learning Methods, MIT AI Lab Technical Memo no 1322, October 1991.", '483'
"Rescorla, R.A., & A.R. Wagner (1972). A theory of Pavlovian conditioning: variations in the effectiveness of reinforcement and non-reinforcement. In: A.H. Black, & W.F. Prokasy (Eds.) Classical conditioning II: current research and theory. New York: Appl", '486'
"Helen G. Cobb (Forthcoming). Toward Understanding Learning Biases in a Collective Reinforcement Learner. D.Sc. dissertation, The George Washington University, Washington, DC.", '492'
"T. W. Sandholm and R. H. Crites. Multiagent reinforcement learning and the iterated prisoner's dilemma. Biosystems Journal, (Submitted), 1995.", '495'
"Chrisman, L. (1993), Notational conventions for the reinforcement learning workshop at ML93, Personal Communication.", '498'
"D. Bertsekas. Talk, 1996. Given at the NSF workshop on reinforcement learning.", '501'
"W. Zhang. Reinforcement Learning for Job-Shop Scheduling. PhD thesis, Oregon State University, 1996.", '504'
"W. Zhang. Reinforcement Learning for Job-Shop Scheduling. PhD thesis, Oregon State University, 1996.", '504'
"Williams, R. J., 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning , 8, 3-4, 229256.", '507'
"Williams, R.J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning, 8, 3-4, 229256.", '507'
"Williams, R. J. (1992). Simple statistical gradientfollowing algorithms for connectionist reinforcement learning. Machine Learning, 8(3), 229256.", '507'
"R.S. Sutton, editor. Reinforcement Learning. Kluwer, 1992.", '510'
"Barto, A. G., Sutton, R. S., & Brouwer, P. S. (1981). Associative search network: A reinforcement learning", '513'
"Mance E. Harmon. Reinforcement learning: A tutorial. http://eureka1.aa.wpafb.af.mil/rltutorial/.", '516'
"David H. Ackley and Michael L. Littman. Generalization and scaling in reinforcement learning. In Touretzky", '519'
"Fiechter, C.-N. (1994) Efficient Reinforcement Learning. COLT 94.", '522'
"Berenji, H. & Khedkar, P. (1992). Learning and tuning fuzzy logic controllers through reinforcements. IEEE Transactions on Neural Networks, 3:724-740.", '525'
"Berenji, H.R. (1992). Learning and tuning fuzzy controllers bthrough reinforcements. In: IEEE Trans. on Neural Networks, vol. 3, 5, pp. 724-740.", '525'
"Berenji, H., & Khedkar, P. 1992. Learning and tuning fuzzy logic controllers through reinforcements. IEEE Trans. on Neural Networks 3:724-740.", '525'
"H. Berenji and P. Khedkar, Learning and Tuning Fuzzy Controllers Through Reinforcements, IEEE Transactions on Neural Networks, vol. 3, no. 5, pp 724-740, 1992.", '525'
"Berenji, H.R. and Khedkar, P. Learning and Tuning Fuzzy Controllers Through Reinforcements, IEEE Transactions on neural networks, vol. 3, No. 5, 724-740, 1992.", '525'
"H. Berenji and P. Khedkar. Learning and tuning fuzzy logic controllers through reinforcements. IEEE Transactions on Neural Networks, 3:724-740, 1992.", '525'
"Berenji, H., & Khedkar, P. (1992). Learning and tuning fuzzy logic controllers through reinforcements. IEEE Transactions on Neural Networks, 3, 724-740.", '525'
"H. Berenji and P. Khedkar, Learning and fine tuning fuzzy logic controllers through reinforcement, IEEE Transactions on Neural Networks, vol. 3, no. 5, pp. 724-740, 1992.", '525'
